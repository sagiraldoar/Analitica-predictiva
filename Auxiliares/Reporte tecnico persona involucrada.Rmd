---
title: "Reporte Técnico"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<style>
body {
text-align: justify}
</style>


## Cargue de los datos

Como primer paso se realiza la carga de los datos, los cuales se encuentran en un dataset diferente para cada año y posteriomente se concatenan para tener centralizada la información y facilitar los análisis

```{r}
wd="C:/Users/sga96/OneDrive/Accidentalidad-Medellin"
  setwd(wd)
  
  df_2014=read.csv("./Datasets/Accidentalidad_georreferenciada_2014.csv",strip.white=TRUE,
                    encoding = "UTF-8")
  df_2015=read.csv("./Datasets/Accidentalidad_georreferenciada_2015.csv",strip.white=TRUE,
                    encoding = "UTF-8")
  df_2016=read.csv("./Datasets/Accidentalidad_georreferenciada_2016.csv",strip.white=TRUE,
                    encoding = "UTF-8")
  df_2017=read.csv("./Datasets/Accidentalidad_georreferenciada_2017.csv",strip.white=TRUE,
                    encoding = "UTF-8")
  df_2018=read.csv("./Datasets/Accidentalidad_georreferenciada_2018.csv",strip.white=TRUE,
                    encoding = "UTF-8")
  
  df_inicial = rbind(df_2014,df_2015,df_2016,df_2017,df_2018)
 
```



## Limpieza de los datos y creación de dataframe inicial

En primera instancia de se realiza una limpieza de los datos inicial,y una agrupación de los registros  para la creación del dataframe final. 


```{r}
# se organiza la columna de la variable fecha
library(tidyr)
df <- separate(data = df_inicial, col = FECHA, into = c("FECHA", "Sobrante"), sep = " ")
df$FECHA <- as.Date(df$FECHA, format = "%Y/%m/%d")

# Se limpian los datos y de la columna GRAVEDAD y se agrupan en 2 categorías
df$GRAVEDAD[df$GRAVEDAD=='MUERTO'] <- "Persona involucrada" 
df$GRAVEDAD[df$GRAVEDAD=='HERIDO'] <- "Persona involucrada"
df$GRAVEDAD[df$GRAVEDAD=='SOLO DAÑOS'] <- "Solo daños" 


#Se agrupa por GRAVEDAD y por día
library(dplyr,warn.conflicts = FALSE)
df <-  df %>%
  group_by(FECHA,PERIODO,MES,DIA,DIA_NOMBRE,GRAVEDAD) %>%
  summarize(NRO_ACCIDENTES=n())
```
A continuación se realiza una breve descripción de las variables iniciales:

- **FECHA**: Fecha en formato AAAA-MM-DD
- **PERIODO**: Entero que corresponde la año respectivo
- **MES**: Entero que corresponde al mes respectivo
- **DIA**: Entero que corresponde al día respectivo
- **DIA_NOMBRE**: Es una cadena de texto que representa el nombre del día
- **CLASE**: Es una agrupación de los tipos de accidente creados para la modelación (Choque, Atropello y Otros)
- **NRO_ACCIDENTES**: Es el número de accidentes presentados en la ciudad para la fecha en cuestión

## Creación de variables adicionales.

Para tener mayores herramientas que permitan una mejor capacidad de predicción de los modelos que se utilizarán más adelante, se crearon una serie de variables que en primera instancia podrían tener en mayor o menor medida influencia en el número de accidentes que se producen día a día:

- **ANIO_REFERENCIA**: Se toma el 2014 como año de referencia y a cada año se le resta este valor, para reducir la cardinalidad de los datos y evitar problemas en los modelos, se toma como variable continua para tener la posibilidad de predecir futuros años.
- **SEMANA**: se obtiene el número de semana de la fecha
- **LABORAL**: 1 Si el día es laboral y 0 si no lo es (SÁBADO,DOMINGO Y FESTIVO)
- **FESTIVO**: 1 Si el día es FESTIVO y 0 si no lo es.
- **HALLOWEEN**: Se celebra el 31 de octubre de cada año, y muchas personas y niños salen en las horas de la noche a pedir dulces lo que puede aumentar el riesgo de accidentes.
- **NAVIDAD** Día que se celebra la navidad, 25 de diciembre
- **FIN_DE_AÑO**: Ultimo día del año que muchas personas no trabajan y hay mucho movimiento en la ciudad
- **FERIA_DE_FLORES**: Evento festivo tradicional en la ciudad que se celebra en Agosto
- **SEMANA_SANTA**: Es la semana que se celebran ceremonias religiosas, usualmente en el mes de abril
- **FIESTA_DEL_TAMARINDO**: Es una fiesta, que se celebra en Santafe de Antioquia, lugar donde muchas personas de la ciudad tienen propiedas
- **FIESTA_DE_LOS_ZOCALOS**: Fiesta en guatape en donde muchas personas se pueden movilizar
- **DIA_DE_LA_MADRE**: Es el segundo Domingo de Mayo, es un día que generalmente tiene altos niveles de accidentalidad y homicidios
- **DIA_SIN_CARRO**: Es un día al año en donde no es permitido movilizarse en transporte particular, lo que se esperaría que se reduzca la accidentalidad
- **MARATÓN_DE_LAS_FLORES**: Es una maraton que se corre en la ciudad de medellin, en donde se cierra muchas vías de la ciudad, lo que puede reducir la accidentalidad



```{r}
#se crea la variable año de referencia
df$ANIO_REFERENCIA <- df$PERIODO -2014

#Se agrega variable semana
df$SEMANA <- format(df$FECHA,"%V")

# Se agregan  variable de FESTIVO al modelo
festivos=read.csv("./Datasets/Festivos.csv")
festivos$FECHA <- as.Date(festivos$FECHA, format = "%Y-%m-%d")
df <- merge(x = df, y = festivos, by = "FECHA", all.x = TRUE)
  
# Se agrega variable LABORAL al modelo
laborales=c('LUNES','MARTES','MIÉRCOLES','JUEVES','VIERNES')
df$LABORAL=ifelse(df$DIA_NOMBRE %in% laborales,1,0)
df$LABORAL=ifelse(df$FESTIVO == 1,0,df$LABORAL)

#Se agregan fechas especiales
df_fechas_especiales=read.csv("./Datasets/Fechas especiales.csv",strip.white=TRUE,
                                      encoding = "UTF-8")
df_fechas_especiales$FECHA <- as.Date(df_fechas_especiales$FECHA, format = "%Y-%m-%d")
df <- merge(x = df, y = df_fechas_especiales, by = "FECHA", all.x = TRUE)

```


## Modelación

Para cumplir el primer objetivo de este proyecto, se buscará predecir la accidentalidad para cada tipo de clase en diferentes temporalidades (diaria, semanal y mensual) Utilizando diferentes técnicas estadistícas y algoritmos de machine learning para la selección de un modelo optimo teniendo en cuenta la información disponible.

###Personas afectadas

Para esto se utiliza el dataframe construido anteriormente y se generarán las variables dummies necesarias para la construcción del modelo, y se evaluará para el tipo de accidente personas involucradas que corresponde a los tipos de gravedad 'Herido" y 'Muerto'

```{r}
#Se selecciona solo la gravedad solo daños
df <- df[df$GRAVEDAD== "Persona involucrada",]
df$GRAVEDAD <- NULL
df$DIA <- sprintf("%02d", df$DIA)
df$MES <- sprintf("%02d", df$MES)
library(fastDummies)

df_modelo <- dummy_cols(df, select_columns = c('MES','SEMANA','DIA','DIA_NOMBRE'))
df_modelo$MES <- NULL
df_modelo$SEMANA <- NULL
df_modelo$DIA <- NULL
df_modelo$DIA_NOMBRE <- NULL


```

Para la evaluación de los modelos, se dividirá el conjunto de datos desde el año 2014 al 2017 para  entrenamiento y 2018 como validación. Adicionalmente se utilizará le medida del error cuadrático medio (MSE) para la comparación de la predicción de los modelos, Sin embargo también se tendrán en cuenta otras medidas para la selección del modelo, como el Número de variables, el R2 ajustado y el AIC.



```{r}
# se divide el conjunto de datos en entrenamiento y validación
train <- df_modelo[df_modelo$PERIODO < 2018,]
validation<- df_modelo[df_modelo$PERIODO == 2018,]

```

### Regresión lineal 

Como primer modelo se utilizará una regresión lineal con todas las variables creadas para tener una linea base sobre la cual comparar y seleccionar variables.
```{r}
# se genera el modelo de regresión lineal, y como una variable categorica se puede representar como k-1 variables dummies, se elimina una de cada variable inicial
modelo_lm <- lm(NRO_ACCIDENTES~.-FECHA-PERIODO-MES_01-SEMANA_01-DIA_01-DIA_NOMBRE_LUNES,data=train)
summary(modelo_lm)
cat(" AIC:",AIC(modelo_lm))
pred=predict(modelo_lm,train)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```

Analizando los resultados de la regresión analizada, según el R2 ajustado, el 39,38% de la variación en los accidentes con personas involucrada esta explicado por las variables utilizadas. Adicionalmente el valor P del estadistico F al ser menor al 5% muestra que al menos una de las variables utilizadas tiene la capacidad de explicar una parte significativa de la variación en los accidentes con personas involucradas.Sin embargo este modelo presenta un inconveniente bastante grande, ya que la desviación entre el MSE de entrenamiento y validación es de aproximadamente el 50.3%, lo que da evidencias clara de un sobreentrenamiento en el modelo.

A continuación se muestra la grafica de las predicciones vs los valores observados de los accidentes con personas involucradas para obtener información adicional 

```{r}
plot(pred,validation$NRO_ACCIDENTES,xlab="Predichos",ylab="Observados",las=1)
abline(a=0,b=1,lwd=2)
grid()
```

En el gráfico de dispersión se observa, que el modelo en niveles mas altos de accidentalidad tiene mayor capacidad de predición que para niveles mas bajos.

El tema del sobre entrenamiento puede ser un problema muy grave para el modelo, ya que esto quiere decir que el modelo esta aprendiendo de memoria los datos, pero no tiene una buena capacidad de generalización. Para afrontar este problema a continuación se realizará una serie de técnicas de selección de variables y regularización para intentar mejorar esta situación.


En primera instancia se utilizará un stepwise para apoyar en la selección de las variables.

```{r}
modelo_lm_step<-step(modelo_lm,direction = "backward",trace=FALSE)
summary(modelo_lm_step)
cat(" AIC:",AIC(modelo_lm))
pred=predict(modelo_lm_step,train)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm_step,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```

Se observa un MSE mas alto utilizando este metodo, adicionalmente el sobre entrenamiento sigue existiendo con una desviación del 54% por lo que esta alternativa no es viable para el modelo.

Se trata de aplicar un método de regularización para revisar si se reduce el sobreentrenamiento del modelo, en este caso se aplicará una regresión lasso, ya que esta tiene la capacidad de penalizar parametros que podrían ser la causa del sobre entrenamiento, e incluso tiene por si mismo un metodo de selección de variables.

```{r}
library(glmnet)
X <-model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
    SEMANA_01 - DIA_01 - DIA_NOMBRE_LUNES,train)[,-1]
y <- train$NRO_ACCIDENTES
#Se optimiza el lambda
grid<-10^seq(10,-4,length=100)
modelo_lasso<-cv.glmnet(X,y,alpha=1,lambda=grid) # alpha=1 es lasso
lambda_opt<-modelo_lasso$lambda.min
modelo_lasso<-glmnet(X,y,alpha=1,lambda = lambda_opt)
```

Se observan los datos de la regularización
```{r}
modelo_lasso$beta
```


```{r}
pred<-predict(modelo_lasso,model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
    SEMANA_01 - DIA_01 - DIA_NOMBRE_LUNES,train)[,-1])
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred<-predict(modelo_lasso,model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
    SEMANA_01 - DIA_01 - DIA_NOMBRE_LUNES,validation)[,-1])
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))

```
Como se puede observar en la parte superior, el modelo sigue sin desempeñarse correctamente aún con la regularización de las variables,dado que el sobre entrenamiento es mayor al 40% aunque comparado con los metodos anteriores esté parametro es mucho mejor


Se intenta probar un método de diferente naturaleza como es el caso de un bosque aleatorio  para analizar su comportamiento y evaluar sus resultados, para ver si presenta alguna mejoría en las medidas y el sobre entrenamiento


```{r}
library(randomForest)
rf_model <- randomForest(NRO_ACCIDENTES~.-FECHA-PERIODO,data=train,ntree=2000)
pred=predict(rf_model,train)
cat(" MSE_t",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict( rf_model,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```

la alternativa del bosque aleatorio aunque mejora el MSE de entrenamiento de forma sustancial  tampoco nos presenta una solución adecuada al sobre entrenamiento, de hecho por el contrario, el sobreentrenamiento se encuentra aun mas marcado con una desviación de más del 450%.

Analizando todos los métodos realizados anteriormente, se evidencia que los modelos se están ajustando demasiado al conjunto de entrenamiento pero no están teniendo  capacidad de generalizar las predicciones en el  conjunto de validación, buscando alternativas para solucionar este problema, se evidencia que la variable semana está tomando demasiada importancia o significancia para los métodos, teniendo en cuenta tanto los valores p de las regresiones lineales iniciales, como la selección de variables realizadas por el método stepwise, adicionalmente genera muchisimas variables dummy esto puede generar problemas en los modelos debido a que genera una matriz muy dispersa. Por esta razón se decide eliminar completamente esta variable y revisar los resultados.


```{r}
df_modelo <- dummy_cols(df, select_columns = c('MES','DIA','DIA_NOMBRE'))
df_modelo$MES <- NULL
df_modelo$SEMANA <- NULL
df_modelo$DIA <- NULL
df_modelo$DIA_NOMBRE <- NULL
```

Se divide de nuevo el conjunto de entrenamiento y validación

```{r}
# se divide el conjunto de datos  en entrenamiento y validación
train <- df_modelo[df_modelo$PERIODO < 2018,]
validation<- df_modelo[df_modelo$PERIODO == 2018,]

```

De nuevo se ajusta un modelo de regresión lineal con todas las variables con excepción de la semana, para analizar el comportamiento.

```{r}
# se genera el modelo de regresión lineal, y como una variable categorica se puede representar como k-1 variables dummies, se elimina una de cada variable inicial

modelo_lm <- lm(NRO_ACCIDENTES~.-FECHA-PERIODO-MES_01-DIA_01-DIA_NOMBRE_LUNES,data=train)
summary(modelo_lm)
cat(" AIC:",AIC(modelo_lm))
pred=predict(modelo_lm,train)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```
Como se puede observar en las metricas del error cuadratico medio, la desviación en el resultado entre el MSE del conjunto validación y el de prueba se redujo al 36% , lo que implica que la variable semana estaba causando de alguna manera un sobreentrenamiento en el modelo. Sin embargo la desviación sigue siendo superior al 15%, por lo que el modelo a pesar de la mejora sigue estando sobreentrenado, adicionalmente el MSE en validación no presenta mejoría alguna.

```{r}
modelo_lm_step<-step(modelo_lm,direction = "backward",trace=FALSE)
summary(modelo_lm)
cat(" AIC:",AIC(modelo_lm_step))
pred=predict(modelo_lm_step,train)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm_step,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```




Al realizar el metdo de stepwise se mejora tanto el MSE como la desviación entre el MSE de validación y entreneamiento, pero persiste el sobre entrenamiento dado que dicha diferencia es del 28%


Se  analiza la posibilidad de una transformación logaritmica  para ver si se  mejora el  comportamiento en los datos

```{r}
hist(df_modelo$NRO_ACCIDENTES)
```

Se observa el según la gráfica anterior, que la gráfica concentra una distribución muy cercana a la Normal,sin embargo se preocedera a realizar la trasnformación par aobservar sus resultados.


```{r}
hist(log(df_modelo$NRO_ACCIDENTES))
```

```{r}
modelo_lm_log <- lm(log(NRO_ACCIDENTES)~. - FECHA - PERIODO - MES_01  - 
    DIA_01 - DIA_NOMBRE_LUNES,data=train)
summary(modelo_lm_log)
cat("AIC_",AIC(modelo_lm_log))
pred=predict(modelo_lm_log,train)
cat(" MSE_t:",mean((exp(pred)-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm_log,validation)
cat(" MSE_v:",mean((exp(pred)-validation$NRO_ACCIDENTES)^2))
```

La transformación logaritmica presenta el mejor MSE analizado hasta el momento, con una reducción considerable, además el sobre entrenamiento baja a niveles cercanos al 21%, es una buena aproximación inicial, pero aún se le deben realizar ajustes para mitigar esta situación.

Con la finalidad de seguir ajustando el modelo con traformación logaritmica se procede a realizar una seleccion de variables por medio del emtodo step wise


```{r}
modelo_lm_log_step<-step(modelo_lm_log,direction = "backward",trace=FALSE)
summary(modelo_lm_log_step)
cat("AIC:",AIC(modelo_lm_log_step))
pred=predict(modelo_lm_log_step,train)
cat(" MSE_t",mean((exp(pred)-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm_log_step,validation)
cat(" MSE_v:",mean((exp(pred)-validation$NRO_ACCIDENTES)^2))
```

Al aplicar la selección de variables a la transformación logaritmica, se lográ cumplir el objetivo trazado inicialmente de logra que la desviación entre el MSE de entrenamiento y validación sea menor al 15%, adicionalmente, el MSE de validación es de 132, es la mejor métrica que se ha obtenido hasta el momento.


Se procede a realizar de nuevo una Regularización lasso , para analizar como se comporta de nuevo esta regresión sin el valor de la semana, para observar esta manera de que impacta la penalización de los parámetros.

```{r}
library(glmnet)
X <-model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
     - DIA_01 - DIA_NOMBRE_LUNES,train)[,-1]
y <- train$NRO_ACCIDENTES
grid<-10^seq(10,-4,length=100)
modelo_lasso<-cv.glmnet(X,y,alpha=1,lambda=grid) # alpha=1 es lasso
lambda_opt<-modelo_lasso$lambda.min
modelo_lasso<-glmnet(X,y,alpha=1,lambda = lambda_opt)
```

```{r}
pred<-predict(modelo_lasso,model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
     - DIA_01 - DIA_NOMBRE_LUNES,train)[,-1])
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred<-predict(modelo_lasso,model.matrix(NRO_ACCIDENTES~.- FECHA - PERIODO - MES_01 - 
     - DIA_01 - DIA_NOMBRE_LUNES,validation)[,-1])
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```
Analizando el MSE en el conjunto de validación, no se encuentra mejoría en comparación con los modelos anteriores, de hecho vuelve a generar un MSE mayor, y sigue generandose un modelo sobreentrenado.


Analizando otras posibilidades se intenta en primera instancia modelar con una maquina de soporte vectorial, con un kernel radial para evaluar sus resultados


```{r}
#Load Library
library(e1071)
 
#Scatter Plot


#Regression with SVM
modelsvm = svm(NRO_ACCIDENTES~.-FECHA-PERIODO,train,kernel="radial")

#Predict using SVM regression
pred = predict(modelsvm, train)
mean((pred-train$NRO_ACCIDENTES)^2)
pred = predict(modelsvm, validation)
mean((pred-validation$NRO_ACCIDENTES)^2)

```
La maquina de soporte presenta un comportamiento similar al árbol, con altos niveles de sobre entrenamiento, con buenos niveles de MSE en el conjunto de entrenamiento  pero poca capacidad predictiva en el conjunto de validación.


se intenta realizar un analisis de sensibilidad con un kernel lineal para validar que impacto tiene sobre los resultados.

```{r}
#Load Library
library(e1071)
 
#Scatter Plot


#Regression with SVM
modelsvm = svm(NRO_ACCIDENTES~.-FECHA-PERIODO,train,kernel="linear")

#Predict using SVM regression
pred = predict(modelsvm, train)
mean((pred-train$NRO_ACCIDENTES)^2)
pred = predict(modelsvm, validation)
mean((pred-validation$NRO_ACCIDENTES)^2)

```
Cambiar el kernel a lineal,disminuye el sobre entrenamiento con respecto al kernel radial, pero igual este vlaor sigue siendo superior al 15% y adicionalmente el MSE de validación es mucho peor.


Debido a que la maquina de soporte vectorial, escala muy bien con el numero de observaciones, pero presenta problemas a medida que el número de variables aumenta, se aplica utilizando las variables elegidas en el stepwise de la transformación logaritmica calculado anteriormente.



```{r}
#Load Library
library(e1071)
 
#Scatter Plot


#Regression with SVM
modelsvm = svm(formula(modelo_lm_log_step),train,kernel="linear")

#Predict using SVM regression
pred = predict(modelsvm, train)
mean((exp(pred)-train$NRO_ACCIDENTES)^2)
pred = predict(modelsvm, validation)
mean((exp(pred)-validation$NRO_ACCIDENTES)^2)

```
Los resultados de la maquina de soporte vectorial mejoran, con respecto al inicial de que utilizaba todas las variables, sin embargo el MSE en el conjunto de validación es superior a metodos anteriormente utilizados, y el sobre entrenamiento sigue siendo superior al 15%


Se intenta utilizar un bosque aleatorio para observar el poder de la predicción.

```{r}
library(randomForest)
rf_model <- randomForest(NRO_ACCIDENTES~.-FECHA-PERIODO,data=train,ntree=2000)
rf_model$importance
pred=predict(rf_model,train)
cat(" MSE_t",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(rf_model,validation)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))


```
al arbol aunque sigue siendo el modelo que de lejos tiene el mejor MSE en entrenamiento, la diferencia con el conjunto de validación sigue siendo demasiado grande, adicionalmente en validación su MSE no mejora con respecto a los demás modelos, por lo que no se considera una opción viable.

Debido a las caracteristicas de los bosques aleatorios, en donde no requieren de variables dummies para su entrenamiento, se prueba creando un modelo con las variables iniciales sin convertirlas en dummy, para asi reducir el problema de la dimensionalidad y ver si esto presenta mejores resultados.

```{r}
train_rf <- df[df$PERIODO < 2018,]
validation_rf<- df[df$PERIODO == 2018,]
```

```{r}
rf_model <- randomForest(NRO_ACCIDENTES~.-FECHA-DIA,data=train_rf,ntree=2000)
summary(rf_model)
pred=predict(rf_model,train_rf)
cat(" MSE_t",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(rf_model,validation_rf)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```
Al parecer esta alternativa reduce un poco el sobre entrenamiento, pero aún asi este sigue existiendo, y el MSE no presenta mejorías.


Se realiza el modelo de regresión lineal con las variables seleccionadas de acuerdo al árbol, tomando como punto de corte aquellas que sean superiores a un valor de 5.000 IncNodePurity

```{r}
# se genera el modelo de regresión lineal, y como una variable categorica se puede representar como k-1 variables dummies, se elimina una de cada variable inicial
df_modelo_importancia_rf=df_modelo[,c('FECHA','PERIODO','ANIO_REFERENCIA','FESTIVO','LABORAL','SEMANA_SANTA','MES_01','DIA_NOMBRE_DOMINGO','NRO_ACCIDENTES')]

train_rf <- df_modelo_importancia_rf[df_modelo_importancia_rf$PERIODO < 2018,]
validation_rf<- df_modelo_importancia_rf[df_modelo_importancia_rf$PERIODO == 2018,]

modelo_lm <- lm(NRO_ACCIDENTES~.-FECHA-PERIODO,data=train_rf)
summary(modelo_lm)
cat(" AIC:",AIC(modelo_lm))
pred=predict(modelo_lm,train_rf)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm,validation_rf)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```
Con esta nueva selección de variables el modelo no presenta una, mejoría en comparación al modelo de transformación logaritmica con selección stepwise

se revisa el modelo con support vector machines con la variables seleccionadas por el bosque aleatorio para revisar si existe alguna mejora.


```{r}
#Load Library
library(e1071)
 
#Scatter Plot


#Regression with SVM
model_svm = svm(NRO_ACCIDENTES~.-FECHA-PERIODO,train_rf,kernel="linear")

#Predict using SVM regression
pred=predict(model_svm,train_rf)
cat(" MSE_t:",mean((pred-train$NRO_ACCIDENTES)^2))
pred=predict(model_svm,validation_rf)
cat(" MSE_v:",mean((pred-validation$NRO_ACCIDENTES)^2))
```
Aplicar selección de variables con base al árbol tampoco presenta una mejora considerable en la maquina de soporte vectorial, por lo que se descarta esta opción

### Selección de modelo

Después de analizar multiples modelos, revisar problemas de sobrentrenamiento y aplicar diferentes metodos de selección de variables y transformaciones, y utilizando principalmente el MSE de validación como métrica para elección del mejor modelo, teniendo en cuenta también el número de variables utilizadas. El modelo de regresión lineal, eliminando inicialmente las variables relacionadas la semana y posteriormente haciendo una selección de variables con un stepwise con el parámetro "backward" y una transformación logaritmica se concluye que esté modelo tiene el menor sobre entrenamiento ya que presenta una desviación del 14.7% entre el MSE de entrenamiento y validación , adicionalmente al interpretar el R2 y se evidencia que  el 41% de la variación en el número de accidentes con personas involucradas es explicado por las variables presentes en el modelo.

```{r}
modelo_lm_log_step<-step(modelo_lm_log,direction = "backward",trace=FALSE)
summary(modelo_lm_log_step)
cat("AIC:",AIC(modelo_lm_log_step))
pred=predict(modelo_lm_log_step,train)
cat(" MSE_t",mean((exp(pred)-train$NRO_ACCIDENTES)^2))
pred=predict(modelo_lm_log_step,validation)
cat(" MSE_v:",mean((exp(pred)-validation$NRO_ACCIDENTES)^2))
```
```{r}
saveRDS(modelo_lm_log_step, "./modelo_diario_personas.rds")
```





```









